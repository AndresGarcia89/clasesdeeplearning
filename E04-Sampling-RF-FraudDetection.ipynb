{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grupo conformado por:\n",
    "Edgar Andrés García Hernández - 200512532\n",
    "John Pablo Calvo López - 201726690"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 04\n",
    "\n",
    "# Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "- Fraud Detection Dataset from Microsoft Azure: [data](http://gallery.cortanaintelligence.com/Experiment/8e9fe4e03b8b4c65b9ca947c72b8e463)\n",
    "\n",
    "Fraud detection is one of the earliest industrial applications of data mining and machine learning. Fraud detection is typically handled as a binary classification problem, but the class population is unbalanced because instances of fraud are usually very rare compared to the overall volume of transactions. Moreover, when fraudulent transactions are discovered, the business typically takes measures to block the accounts from transacting to prevent further losses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('../datasets/fraud_detection.csv.zip', 'r') as z:\n",
    "    f = z.open('15_fraud_detection.csv')\n",
    "    data = pd.io.parsers.read_table(f, index_col=0, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accountAge</th>\n",
       "      <th>digitalItemCount</th>\n",
       "      <th>sumPurchaseCount1Day</th>\n",
       "      <th>sumPurchaseAmount1Day</th>\n",
       "      <th>sumPurchaseAmount30Day</th>\n",
       "      <th>paymentBillingPostalCode - LogOddsForClass_0</th>\n",
       "      <th>accountPostalCode - LogOddsForClass_0</th>\n",
       "      <th>paymentBillingState - LogOddsForClass_0</th>\n",
       "      <th>accountState - LogOddsForClass_0</th>\n",
       "      <th>paymentInstrumentAgeInAccount</th>\n",
       "      <th>ipState - LogOddsForClass_0</th>\n",
       "      <th>transactionAmount</th>\n",
       "      <th>transactionAmountUSD</th>\n",
       "      <th>ipPostalCode - LogOddsForClass_0</th>\n",
       "      <th>localHour - LogOddsForClass_0</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>720.25</td>\n",
       "      <td>5.064533</td>\n",
       "      <td>0.421214</td>\n",
       "      <td>1.312186</td>\n",
       "      <td>0.566395</td>\n",
       "      <td>3279.574306</td>\n",
       "      <td>1.218157</td>\n",
       "      <td>599.00</td>\n",
       "      <td>626.164650</td>\n",
       "      <td>1.259543</td>\n",
       "      <td>4.745402</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1185.44</td>\n",
       "      <td>2530.37</td>\n",
       "      <td>0.538996</td>\n",
       "      <td>0.481838</td>\n",
       "      <td>4.401370</td>\n",
       "      <td>4.500157</td>\n",
       "      <td>61.970139</td>\n",
       "      <td>4.035601</td>\n",
       "      <td>1185.44</td>\n",
       "      <td>1185.440000</td>\n",
       "      <td>3.981118</td>\n",
       "      <td>4.921349</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.064533</td>\n",
       "      <td>5.096396</td>\n",
       "      <td>3.056357</td>\n",
       "      <td>3.155226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.314186</td>\n",
       "      <td>32.09</td>\n",
       "      <td>32.090000</td>\n",
       "      <td>5.008490</td>\n",
       "      <td>4.742303</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.064533</td>\n",
       "      <td>5.096396</td>\n",
       "      <td>3.331154</td>\n",
       "      <td>3.331239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.529398</td>\n",
       "      <td>133.28</td>\n",
       "      <td>132.729554</td>\n",
       "      <td>1.324925</td>\n",
       "      <td>4.745402</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>132.73</td>\n",
       "      <td>5.412885</td>\n",
       "      <td>0.342945</td>\n",
       "      <td>5.563677</td>\n",
       "      <td>4.086965</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>3.529398</td>\n",
       "      <td>543.66</td>\n",
       "      <td>543.660000</td>\n",
       "      <td>2.693451</td>\n",
       "      <td>4.876771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accountAge  digitalItemCount  sumPurchaseCount1Day  sumPurchaseAmount1Day  \\\n",
       "0        2000                 0                     0                   0.00   \n",
       "1          62                 1                     1                1185.44   \n",
       "2        2000                 0                     0                   0.00   \n",
       "3           1                 1                     0                   0.00   \n",
       "4           1                 1                     0                   0.00   \n",
       "\n",
       "   sumPurchaseAmount30Day  paymentBillingPostalCode - LogOddsForClass_0  \\\n",
       "0                  720.25                                      5.064533   \n",
       "1                 2530.37                                      0.538996   \n",
       "2                    0.00                                      5.064533   \n",
       "3                    0.00                                      5.064533   \n",
       "4                  132.73                                      5.412885   \n",
       "\n",
       "   accountPostalCode - LogOddsForClass_0  \\\n",
       "0                               0.421214   \n",
       "1                               0.481838   \n",
       "2                               5.096396   \n",
       "3                               5.096396   \n",
       "4                               0.342945   \n",
       "\n",
       "   paymentBillingState - LogOddsForClass_0  accountState - LogOddsForClass_0  \\\n",
       "0                                 1.312186                          0.566395   \n",
       "1                                 4.401370                          4.500157   \n",
       "2                                 3.056357                          3.155226   \n",
       "3                                 3.331154                          3.331239   \n",
       "4                                 5.563677                          4.086965   \n",
       "\n",
       "   paymentInstrumentAgeInAccount  ipState - LogOddsForClass_0  \\\n",
       "0                    3279.574306                     1.218157   \n",
       "1                      61.970139                     4.035601   \n",
       "2                       0.000000                     3.314186   \n",
       "3                       0.000000                     3.529398   \n",
       "4                       0.001389                     3.529398   \n",
       "\n",
       "   transactionAmount  transactionAmountUSD  ipPostalCode - LogOddsForClass_0  \\\n",
       "0             599.00            626.164650                          1.259543   \n",
       "1            1185.44           1185.440000                          3.981118   \n",
       "2              32.09             32.090000                          5.008490   \n",
       "3             133.28            132.729554                          1.324925   \n",
       "4             543.66            543.660000                          2.693451   \n",
       "\n",
       "   localHour - LogOddsForClass_0  Label  \n",
       "0                       4.745402      0  \n",
       "1                       4.921349      0  \n",
       "2                       4.742303      0  \n",
       "3                       4.745402      0  \n",
       "4                       4.876771      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((138721, 16), 797, 0.0057453449730033666)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, data.Label.sum(), data.Label.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['Label'], axis=1)\n",
    "y = data['Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 04.1\n",
    "\n",
    "Estimate a Logistic Regression\n",
    "\n",
    "Evaluate using the following metrics:\n",
    "* Accuracy\n",
    "* F1-Score\n",
    "* F_Beta-Score (Beta=10)\n",
    "\n",
    "Comment about the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9939736455119518\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AndresGarcia\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[34472,     0],\n",
       "       [  209,     0]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg=LogisticRegression()\n",
    "logreg.fit(X_train,y_train)\n",
    "y_pred_class=logreg.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))\n",
    "print(metrics.f1_score(y_test,y_pred_class))\n",
    "print(metrics.fbeta_score(y_test,y_pred_class,beta=10))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se observó que el modelo tiene un serio problema con la sensibilidad. Lo anterior se debe en parte al desbalance en la muestra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 04.2\n",
    "\n",
    "Under-sample the negative class using random-under-sampling\n",
    "\n",
    "Which is parameter for target_percentage did you choose?\n",
    "How the results change?\n",
    "\n",
    "**Only apply under-sampling to the training set, evaluate using the whole test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7244600790057957\n",
      "0.02150317427810772\n",
      "0.34819581705355085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[25020,  9452],\n",
       "       [  104,   105]], dtype=int64)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def UnderSampling(X, y, target_percentage=0.5, seed=None):\n",
    "    # Assuming minority class is the positive\n",
    "    n_samples = y.shape[0]\n",
    "    n_samples_0 = (y == 0).sum()\n",
    "    n_samples_1 = (y == 1).sum()\n",
    "\n",
    "    n_samples_0_new =  n_samples_1 / target_percentage - n_samples_1\n",
    "    n_samples_0_new_per = n_samples_0_new / n_samples_0\n",
    "\n",
    "    filter_ = y == 0\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    rand_1 = np.random.binomial(n=1, p=n_samples_0_new_per, size=n_samples)\n",
    "    \n",
    "    filter_ = filter_ & rand_1\n",
    "    filter_ = filter_ | (y == 1)\n",
    "    filter_ = filter_.astype(bool)\n",
    "    \n",
    "    return X[filter_], y[filter_]\n",
    "\n",
    "X_u,y_u=UnderSampling(X_train,y_train,0.433,1)\n",
    "\n",
    "logreg=LogisticRegression()\n",
    "logreg.fit(X_u,y_u)\n",
    "y_pred_class2=logreg.predict(X_test)\n",
    "\n",
    "print(metrics.accuracy_score(y_test, y_pred_class2))\n",
    "print(metrics.f1_score(y_test,y_pred_class2))\n",
    "print(metrics.fbeta_score(y_test,y_pred_class2,beta=10))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred_class2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se eligió un porcentaje de 43.3% para el porcentaje objetivo. Lo anterior se debió a una meta particular.\n",
    "Específicamente, se buscó identificar al menos el 50% de los fraudes minimizando el número de falsos positivos.\n",
    "Este número de fraudes a identificar con el modelo se eligió como política externa, buscando garantizar un mínimo de sensibilidad.\n",
    "Valores más altos para la división de la muestra habrían aumentado el número de falsos positivos de forma desproporcionada.\n",
    "Cabe mencionar, por otro lado, que una división de la muestra al 30% arrojaba el valor máximo para el puntaje F1 y alta precisión.\n",
    "Sin embargo, detección de fraudes con esa división era muy baja (apenas 31 de los 209 en la muestra de prueba)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 04.3\n",
    "\n",
    "Now using random-over-sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a problemas con el código mostrado en clase, el cual estaba generando NA para la variable dependiente al hacer el oversampling, dado un resultado np.isnan(y_o).any()=True, se utilizó el paquete imblearn para rebalancear la muestra.\n",
    "http://contrib.scikit-learn.org/imbalanced-learn/stable/over_sampling.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AndresGarcia\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function _ratio_float is deprecated; Use a float for 'ratio' is deprecated from version 0.2. The support will be removed in 0.4. Use a dict, str, or a callable instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7844641157982757\n",
      "0.02808477441164998\n",
      "0.38432809527165107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[27098,  7374],\n",
       "       [  101,   108]], dtype=int64)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros1=RandomOverSampler(ratio=.79, random_state=1)\n",
    "# En esta función, \"ratio\" no opera en forma porcentual sino como una tasa\n",
    "# Es decir, un ratio de 1 hará que la muestra con oversampling tenga participaciones iguales para ambas categorías\n",
    "# Un ratio 1 es equivalente a poner 0.5 en target_percentage para la función anterior\n",
    "X_o,y_o=ros1.fit_sample(X_train,y_train)\n",
    "\n",
    "logreg.fit(X_o,y_o)\n",
    "y_pred_class3=logreg.predict(X_test)\n",
    "\n",
    "print(metrics.accuracy_score(y_test, y_pred_class3))\n",
    "print(metrics.f1_score(y_test,y_pred_class3))\n",
    "print(metrics.fbeta_score(y_test,y_pred_class3,beta=10))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred_class3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se eligió un ratio de 0.79, equivalente a un porcentaje de 39.5% para el objetivo. Nuevamente, se buscó identificar al menos el 50% de los fraudes minimizando el número de falsos positivos. Y este fue el ratio más bajo con el cual se cumplió esta meta. Nuevamente, valores más altos para el ratio disminuían los indicadores del modelo, al tiempo que ratios más bajos aumentaban la precisión y las F, a costa de una menor sensibilidad a fraudes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 04.4*\n",
    "Evaluate the results using SMOTE\n",
    "\n",
    "Which parameters did you choose?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuevamente, hubo problemas con el código mostrado en clase. Lo anterior se debió a problemas con las variables dentro de la función. Por ello, nuevamente se utilizó imblearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AndresGarcia\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function _ratio_float is deprecated; Use a float for 'ratio' is deprecated from version 0.2. The support will be removed in 0.4. Use a dict, str, or a callable instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7809463394942475\n",
      "0.0281437891774338\n",
      "0.3897151676722323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[26974,  7498],\n",
       "       [   99,   110]], dtype=int64)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote1=SMOTE(ratio=0.757, random_state=1)\n",
    "# En esta función, \"ratio\" no opera en forma porcentual sino como una tasa\n",
    "# Es decir, un ratio de 1 hará que la muestra con oversampling tenga participaciones iguales para ambas categorías\n",
    "# Un ratio 1 es equivalente a poner 0.5 en target_percentage para la función anterior\n",
    "\n",
    "X_s,y_s=smote1.fit_sample(X_train,y_train)\n",
    "\n",
    "logreg.fit(X_s,y_s)\n",
    "y_pred_class4=logreg.predict(X_test)\n",
    "\n",
    "print(metrics.accuracy_score(y_test, y_pred_class4))\n",
    "print(metrics.f1_score(y_test,y_pred_class4))\n",
    "print(metrics.fbeta_score(y_test,y_pred_class4,beta=10))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred_class4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se eligió un ratio de 0.757, equivalente a un porcentaje de 37.85% para el objetivo. Nuevamente, se buscó identificar al menos el 50% de los fraudes minimizando el número de falsos positivos. Y este fue el ratio más bajo con el cual se cumplió esta meta. Nuevamente, valores más altos para el ratio disminuían los indicadores del modelo, al tiempo que ratios más bajos aumentaban la precisión y las F, a costa de una menor sensibilidad a fraudes. Comparando con el oversampling, con el SMOTE obtuvo unos indicadores beta ligeramente más altos a costa de una precisión menor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 04.5\n",
    "\n",
    "Estimate a Logistic Regression, GaussianNB, K-nearest neighbors and a Decision Tree **Classifiers**\n",
    "\n",
    "Evaluate using the following metrics:\n",
    "* Accuracy\n",
    "* F1-Score\n",
    "* F_Beta-Score (Beta=10)\n",
    "\n",
    "Comment about the results\n",
    "\n",
    "Combine the classifiers and comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.9939736455119518 0.0 0.0\n",
      "dt 0.9888411522159107 0.14190687361419066 0.15287106234036513\n",
      "nb 0.9913785646319311 0.0 0.0\n",
      "nn 0.9937429716559499 0.1422924901185771 0.08680290297937356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AndresGarcia\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "models = {'lr': LogisticRegression(),\n",
    "          'dt': DecisionTreeClassifier(),\n",
    "          'nb': GaussianNB(),\n",
    "          'nn': KNeighborsClassifier()}\n",
    "\n",
    "for model in models.keys():\n",
    "    models[model].fit(X_train, y_train)\n",
    "    \n",
    "y_pred = pd.DataFrame(index=y_test.index, columns=models.keys())\n",
    "for model in models.keys():\n",
    "    y_pred[model] = models[model].predict(X_test)\n",
    "    \n",
    "for model in models.keys():\n",
    "    print(model,metrics.accuracy_score(y_test,y_pred[model]),metrics.f1_score(y_test,y_pred[model]),metrics.fbeta_score(y_test,y_pred[model],beta=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acuerdo con lo anterior, el modelo con mejores puntajes en general es el árbol de decisiones, debido a que es el modelo con el mejor puntaje F-beta, el segundo mejor F1 (con muy poca diferencia), y muy buena precisión.\n",
    "\n",
    "Sin embargo, en general se observa que los modelos presentan mpuntajes bajos, lo cual habla de su poca especificidad. Lo anterior va ligado al uso de la muestra desbalanceada original.\n",
    "\n",
    "Al mismo tiempo, se aprecia que el modelo de árboles de decisión obtuvo mejores resultados que el modelo de regresión logística original, haciéndolo más adecuado para la predicción de fraudes dada la información disponible.\n",
    "\n",
    "A continuación se combinan los valores obtenidos, redondeando hacia arriba. En este caso, si uno de los modelos clasificaba la transacción como fraude, se redondeaba la variable dependiente hacia arriba, para indicar fraude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9859288947838875\n",
      "F1 Score 0.13780918727915192\n",
      "F-Beta 0.18530366467516582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[34154,   318],\n",
       "       [  170,    39]], dtype=int64)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Accuracy\",metrics.accuracy_score(y_test,np.ceil(y_pred.mean(axis=1))))\n",
    "print(\"F1 Score\",metrics.f1_score(y_test,np.ceil(y_pred.mean(axis=1))))\n",
    "print(\"F-Beta\",metrics.fbeta_score(y_test,np.ceil(y_pred.mean(axis=1)),beta=10))\n",
    "\n",
    "confusion_matrix(y_test, np.ceil(y_pred.mean(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observan los problemas con la combinación. Al tiempo que el F-Beta mejoró frente al modelo de árboles de decisión, los puntajes para la prueba F1 y la precisión empeoraron. Lo anterior se observa también en la matriz de confusión: al modelo le falta sensibilidad, detectando apenas 39 de los 209 fraudes en la muestra de pruebas. Nuevamente, esto se ve influenciado por el uso de la base origina, sin técnicas de rebalanceo de clases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 04.6\n",
    "\n",
    "Using the under-sampled dataset\n",
    "\n",
    "Evaluate a RandomForestClassifier and compare the results\n",
    "\n",
    "change n_estimators=100, what happened"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este ejercicio, se utilizó el AUC como criterio para seleccionar el número óptimo de estimadores. Se buscó maximizar el mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Para este ejercicio se utilizó un bucle, con la finalidad de cambiar el número de estimadores definido en un rango, entre 5 y 200, con saltos de cinco en cinco para dicho número. Así, se obtuvo un AUC máximo de 0.75202306899657, con 150 estimadores\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfclas = RandomForestClassifier()\n",
    "estimator_range = range(1, 201, 5)\n",
    "\n",
    "# list to store the average RMSE for each value of n_estimators\n",
    "AUC_scores = []\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "for estimator in estimator_range:\n",
    "    rfclas = RandomForestClassifier(n_estimators=estimator, random_state=1, n_jobs=-1)\n",
    "    rfclas.fit(X_u,y_u)\n",
    "    AUC_scores.append(metrics.roc_auc_score(y_test,rfclas.predict(X_test)))\n",
    "    \n",
    "print()\n",
    "print(\"Para este ejercicio se utilizó un bucle, con la finalidad de cambiar el número de estimadores definido en un rango, entre 5 y 200, con saltos de cinco en cinco para dicho número. Así, se obtuvo un AUC máximo de \"+str(max(AUC_scores))+\", con \"+str((AUC_scores.index(max(AUC_scores))+1)*5)+\" estimadores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ver el AUC con un número de estimadores igual a 100, se extrajo el valor asociado a 100 estimadores en el vector de AUC, el cual está almacenado como el número 20 en el vector. Dado que Python almacena la primera posición del vector como un cero, el AUC para el número de estimadores 100 estará en la posición 19. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.745672793452227"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC_scores[19]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acuerdo con lo anterior, definir un número de estimadores igual a 100 disminuye ligeramente el AUC del modelo, frente a los 150 estimadores hallados como óptimos.\n",
    "\n",
    "Finalmente, se estimó la matriz de confusión y los indicadores de precisión para el modelo random forest con 150 estimadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8470920677027768\n",
      "0.048789237668161435\n",
      "0.5229574354679052\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[29242,  5230],\n",
       "       [   73,   136]], dtype=int64)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfclasfinal = RandomForestClassifier(n_estimators=150, random_state=1, n_jobs=-1)\n",
    "rfclasfinal.fit(X_u,y_u)\n",
    "y_pred_rf=rfclasfinal.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred_rf))\n",
    "print(metrics.f1_score(y_test,y_pred_rf))\n",
    "print(metrics.fbeta_score(y_test,y_pred_rf,beta=10))\n",
    "\n",
    "confusion_matrix(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando con el modelo de regresión logística hallado utilizando esta misma muestra, el modelo random forest obtuvo resultados mucho mejores en la clasificación. La precisión, el F1 y el F-beta fueron más altos, a su vez que aumentó la sensibilidad del modelo. Igualmente, se observa una menor cantidad de falsos positivos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
